{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section Hierarchy Detection\n",
    "\n",
    "This notebook builds on the parsed PDF data to detect headings and create a hierarchical section structure.\n",
    "\n",
    "## Goals:\n",
    "- Analyze font sizes and styles to identify headings\n",
    "- Classify blocks as H1, H2, H3, or body text\n",
    "- Build a table of contents (TOC)\n",
    "- Assign `section_path` to each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PDF and Extract Font Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 95 pages\n"
     ]
    }
   ],
   "source": [
    "pdf_path = Path(\"../resources/chess.pdf\")\n",
    "doc = pymupdf.open(pdf_path)\n",
    "\n",
    "print(f\"Loaded: {len(doc)} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Blocks with Font Metadata\n",
    "\n",
    "We need font size, font name, and other styling info to detect headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1943 blocks with font metadata\n"
     ]
    }
   ],
   "source": [
    "def extract_blocks_with_fonts(page, page_num):\n",
    "    \"\"\"Extract text blocks with detailed font information.\"\"\"\n",
    "    blocks_data = []\n",
    "    blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "    \n",
    "    for block_idx, block in enumerate(blocks):\n",
    "        if block[\"type\"] == 0:  # text block\n",
    "            bbox = block[\"bbox\"]\n",
    "            text_parts = []\n",
    "            font_sizes = []\n",
    "            font_names = []\n",
    "            is_bold = []\n",
    "            \n",
    "            for line in block.get(\"lines\", []):\n",
    "                for span in line.get(\"spans\", []):\n",
    "                    text_parts.append(span[\"text\"])\n",
    "                    font_sizes.append(span[\"size\"])\n",
    "                    font_names.append(span[\"font\"])\n",
    "                    is_bold.append(\"Bold\" in span[\"font\"] or \"bold\" in span[\"font\"])\n",
    "            \n",
    "            if text_parts:\n",
    "                text = \" \".join(text_parts).strip()\n",
    "                # Use the most common (or max) font size in the block\n",
    "                avg_font_size = max(font_sizes) if font_sizes else 12.0\n",
    "                primary_font = font_names[0] if font_names else \"unknown\"\n",
    "                has_bold = any(is_bold)\n",
    "                \n",
    "                blocks_data.append({\n",
    "                    \"page_num\": page_num,\n",
    "                    \"block_idx\": block_idx,\n",
    "                    \"bbox\": bbox,\n",
    "                    \"text\": text,\n",
    "                    \"font_size\": avg_font_size,\n",
    "                    \"font_name\": primary_font,\n",
    "                    \"is_bold\": has_bold,\n",
    "                    \"char_count\": len(text)\n",
    "                })\n",
    "    \n",
    "    return blocks_data\n",
    "\n",
    "# Extract from all pages\n",
    "all_blocks = []\n",
    "for page_num in range(len(doc)):\n",
    "    page = doc[page_num]\n",
    "    blocks = extract_blocks_with_fonts(page, page_num)\n",
    "    all_blocks.extend(blocks)\n",
    "\n",
    "print(f\"Extracted {len(all_blocks)} blocks with font metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Font Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Font size distribution (top 10):\n",
      "  9.8pt: 1753 blocks\n",
      "  8.0pt: 190 blocks\n",
      "\n",
      "Most common (body text) size: 9.8pt\n"
     ]
    }
   ],
   "source": [
    "# Get font size distribution\n",
    "font_sizes = [b[\"font_size\"] for b in all_blocks]\n",
    "size_counts = Counter([round(fs, 1) for fs in font_sizes])\n",
    "\n",
    "print(\"Font size distribution (top 10):\")\n",
    "for size, count in size_counts.most_common(10):\n",
    "    print(f\"  {size}pt: {count} blocks\")\n",
    "\n",
    "# Find the most common (body text) size\n",
    "body_text_size = size_counts.most_common(1)[0][0]\n",
    "print(f\"\\nMost common (body text) size: {body_text_size}pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Blocks as Headings or Body Text\n",
    "\n",
    "Heuristic:\n",
    "- Larger font size than body text → potential heading\n",
    "- Bold text → potential heading\n",
    "- Short text (< 100 chars) → more likely a heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block classification:\n",
      "  skip: 410\n",
      "  body: 1039\n",
      "  h1: 66\n",
      "  h3: 6\n",
      "  h2: 422\n"
     ]
    }
   ],
   "source": [
    "def classify_block(block, body_size):\n",
    "    \"\"\"Classify a block as heading level or body text.\n",
    "    \n",
    "    For plain text PDFs (like Project Gutenberg exports), use pattern-based detection\n",
    "    since font properties are uniform.\n",
    "    \"\"\"\n",
    "    font_size = block[\"font_size\"]\n",
    "    is_bold = block[\"is_bold\"]\n",
    "    char_count = block[\"char_count\"]\n",
    "    text = block[\"text\"]\n",
    "    \n",
    "    # Skip very short blocks (likely page numbers, etc.)\n",
    "    if char_count < 5:\n",
    "        return \"skip\"\n",
    "    \n",
    "    # Pattern-based heading detection (for uniform font PDFs)\n",
    "    is_all_caps = text.isupper() and len(text) > 5\n",
    "    is_short = len(text) < 100\n",
    "    has_chapter = text.startswith(\"CHAPTER\") or text.startswith(\"PART\")\n",
    "    has_number_prefix = len(text) > 2 and text[0].isdigit() and \". \" in text[:5]\n",
    "    is_underscored = text.startswith(\"_\") and text.endswith(\"_\")\n",
    "    \n",
    "    # Filter out common non-heading patterns\n",
    "    skip_patterns = [\n",
    "        \"illustration\",\n",
    "        \"http://\", \"https://\",\n",
    "        \"gutenberg\",\n",
    "        \"***\",\n",
    "        \"copyright\",\n",
    "        \"printed in\",\n",
    "        \"/\",  # Date patterns like 02/10/2025\n",
    "    ]\n",
    "    \n",
    "    is_noise = any(pattern in text.lower() for pattern in skip_patterns)\n",
    "    \n",
    "    if is_noise:\n",
    "        return \"skip\"\n",
    "    \n",
    "    # Classify headings by pattern\n",
    "    if has_chapter:\n",
    "        return \"h1\"\n",
    "    elif has_number_prefix and is_short:\n",
    "        # Numbered sections like \"1. SOME SIMPLE MATES\"\n",
    "        return \"h2\"\n",
    "    elif is_all_caps and is_short and char_count > 10:\n",
    "        # All caps titles\n",
    "        return \"h1\"\n",
    "    elif is_underscored and is_short:\n",
    "        # Emphasized with underscores\n",
    "        return \"h3\"\n",
    "    \n",
    "    # Font-based detection (fallback for PDFs with proper typography)\n",
    "    size_diff = font_size - body_size\n",
    "    \n",
    "    if size_diff > 4:\n",
    "        return \"h1\"\n",
    "    elif size_diff > 2:\n",
    "        return \"h2\"\n",
    "    elif size_diff > 0.5 and (is_bold or char_count < 80):\n",
    "        return \"h3\"\n",
    "    elif is_bold and char_count < 60:\n",
    "        return \"h3\"\n",
    "    \n",
    "    return \"body\"\n",
    "\n",
    "# Classify all blocks\n",
    "for block in all_blocks:\n",
    "    block[\"type\"] = classify_block(block, body_text_size)\n",
    "\n",
    "# Count classifications\n",
    "type_counts = Counter([b[\"type\"] for b in all_blocks])\n",
    "print(\"Block classification:\")\n",
    "for block_type, count in type_counts.items():\n",
    "    print(f\"  {block_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Sample Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H1 examples (66 total):\n",
      "  Page 0: CHESS FUNDAMENTALS\n",
      "  Page 0: JOSE R. CAPABLANCA\n",
      "  Page 0: _CHESS CHAMPION OF THE WORLD_\n",
      "  Page 0: NEW YORK HARCOURT, BRACE & WORLD, INC. LONDON: G. BELL AND SONS, LTD.\n",
      "  Page 0: HARCOURT, BRACE & WORLD, INC.\n",
      "\n",
      "H2 examples (422 total):\n",
      "  Page 1: 1. SOME SIMPLE MATES                                       3\n",
      "  Page 1: 2. PAWN PROMOTION                                          9\n",
      "  Page 1: 3. PAWN ENDINGS                                           13\n",
      "  Page 1: 4. SOME WINNING POSITIONS IN THE MIDDLE-GAME              19\n",
      "  Page 1: 5. RELATIVE VALUE OF THE PIECES                           24\n",
      "\n",
      "H3 examples (6 total):\n",
      "  Page 0: _Seventeenth Printing_\n",
      "  Page 1: _New York_\n",
      "  Page 1: _Sept. 1, 1934_\n",
      "  Page 15: _A unit that holds two._\n",
      "  Page 27: _The winning of a Pawn among good players of even strength often means the winni\n"
     ]
    }
   ],
   "source": [
    "# Show first few headings of each type\n",
    "for heading_type in [\"h1\", \"h2\", \"h3\"]:\n",
    "    headings = [b for b in all_blocks if b[\"type\"] == heading_type]\n",
    "    print(f\"\\n{heading_type.upper()} examples ({len(headings)} total):\")\n",
    "    for h in headings[:5]:\n",
    "        print(f\"  Page {h['page_num']}: {h['text'][:80]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Section Hierarchy\n",
    "\n",
    "Walk through blocks in order and build a tree structure based on heading levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built section hierarchy with 494 TOC entries\n"
     ]
    }
   ],
   "source": [
    "def build_section_tree(blocks):\n",
    "    \"\"\"Build hierarchical section structure from classified blocks.\"\"\"\n",
    "    # Track current section path at each level\n",
    "    current_path = [None, None, None]  # [h1, h2, h3]\n",
    "    section_map = {}  # block_idx -> section_path\n",
    "    toc = []  # Table of contents\n",
    "    \n",
    "    for block in blocks:\n",
    "        block_key = (block[\"page_num\"], block[\"block_idx\"])\n",
    "        \n",
    "        if block[\"type\"] == \"h1\":\n",
    "            current_path[0] = block[\"text\"]\n",
    "            current_path[1] = None\n",
    "            current_path[2] = None\n",
    "            toc.append({\"level\": 1, \"title\": block[\"text\"], \"page\": block[\"page_num\"]})\n",
    "            \n",
    "        elif block[\"type\"] == \"h2\":\n",
    "            current_path[1] = block[\"text\"]\n",
    "            current_path[2] = None\n",
    "            toc.append({\"level\": 2, \"title\": block[\"text\"], \"page\": block[\"page_num\"]})\n",
    "            \n",
    "        elif block[\"type\"] == \"h3\":\n",
    "            current_path[2] = block[\"text\"]\n",
    "            toc.append({\"level\": 3, \"title\": block[\"text\"], \"page\": block[\"page_num\"]})\n",
    "        \n",
    "        # Build section path from current hierarchy\n",
    "        path_parts = [p for p in current_path if p is not None]\n",
    "        section_path = \" > \".join(path_parts) if path_parts else None\n",
    "        section_map[block_key] = section_path\n",
    "    \n",
    "    return section_map, toc\n",
    "\n",
    "section_map, toc = build_section_tree(all_blocks)\n",
    "print(f\"Built section hierarchy with {len(toc)} TOC entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Table of Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE OF CONTENTS\n",
      "==================================================\n",
      "CHESS FUNDAMENTALS (p.0)\n",
      "JOSE R. CAPABLANCA (p.0)\n",
      "_CHESS CHAMPION OF THE WORLD_ (p.0)\n",
      "NEW YORK HARCOURT, BRACE & WORLD, INC. LONDON: G. BELL AND S (p.0)\n",
      "HARCOURT, BRACE & WORLD, INC. (p.0)\n",
      "    _Seventeenth Printing_ (p.0)\n",
      "J. R. CAPABLANCA (p.1)\n",
      "    _New York_ (p.1)\n",
      "    _Sept. 1, 1934_ (p.1)\n",
      "LIST OF CONTENTS (p.1)\n",
      "PART I (p.1)\n",
      "CHAPTER I (p.1)\n",
      "  1. SOME SIMPLE MATES                                       3 (p.1)\n",
      "  2. PAWN PROMOTION                                          9 (p.1)\n",
      "  3. PAWN ENDINGS                                           13 (p.1)\n",
      "  4. SOME WINNING POSITIONS IN THE MIDDLE-GAME              19 (p.1)\n",
      "  5. RELATIVE VALUE OF THE PIECES                           24 (p.1)\n",
      "  6. GENERAL STRATEGY OF THE OPENING                        25 (p.1)\n",
      "  7. CONTROL OF THE CENTRE                                  28 (p.1)\n",
      "  8. TRAPS                                                  32 (p.1)\n",
      "CHAPTER II (p.1)\n",
      "FURTHER PRINCIPLES IN END-GAME PLAY (p.1)\n",
      "  9. A CARDINAL PRINCIPLE                                   35 (p.1)\n",
      "  10. A CLASSICAL ENDING                                    37 (p.2)\n",
      "  11. OBTAINING A PASSED PAWN                               40 (p.2)\n",
      "  12. HOW TO FIND OUT WHICH PAWN WILL BE THE FIRST TO QUEEN 41 (p.2)\n",
      "  13. THE OPPOSITION                                        43 (p.2)\n",
      "  14. THE RELATIVE VALUE OF KNIGHT AND BISHOP               50 (p.2)\n",
      "  15. HOW TO MATE WITH KNIGHT AND BISHOP                    59 (p.2)\n",
      "  16. QUEEN AGAINST ROOK                                    62 (p.2)\n",
      "\n",
      "... and 464 more entries\n"
     ]
    }
   ],
   "source": [
    "print(\"TABLE OF CONTENTS\\n\" + \"=\"*50)\n",
    "for entry in toc[:30]:  # Show first 30 entries\n",
    "    indent = \"  \" * (entry[\"level\"] - 1)\n",
    "    print(f\"{indent}{entry['title'][:60]} (p.{entry['page']})\")\n",
    "\n",
    "if len(toc) > 30:\n",
    "    print(f\"\\n... and {len(toc) - 30} more entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Section Paths to All Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned section paths to 1934/1943 blocks\n"
     ]
    }
   ],
   "source": [
    "# Attach section_path to each block\n",
    "for block in all_blocks:\n",
    "    block_key = (block[\"page_num\"], block[\"block_idx\"])\n",
    "    block[\"section_path\"] = section_map.get(block_key)\n",
    "\n",
    "# Count blocks with section paths\n",
    "blocks_with_sections = sum(1 for b in all_blocks if b[\"section_path\"])\n",
    "print(f\"Assigned section paths to {blocks_with_sections}/{len(all_blocks)} blocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Blocks with Section Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample body text blocks with section paths:\n",
      "\n",
      "Page 2\n",
      "Section: FURTHER OPENINGS AND MIDDLE-GAMES > 31. SOME SALIENT POINTS ABOUT PAWNS                      143\n",
      "Text: 32. SOME POSSIBLE DEVELOPMENTS FROM A RUY LOPEZ   (showing the weakness of a backward Q B P; the   p...\n",
      "\n",
      "Page 3\n",
      "Section: ILLUSTRATIVE GAMES\n",
      "Text: GAME....\n",
      "\n",
      "Page 3\n",
      "Section: ILLUSTRATIVE GAMES\n",
      "Text: 1. QUEEN'S GAMBIT DECLINED (MATCH, 1909)                159       White: F. J. Marshall. Black: J. R...\n",
      "\n",
      "Page 3\n",
      "Section: ILLUSTRATIVE GAMES\n",
      "Text: 2. QUEEN'S GAMBIT DECLINED (SAN SEBASTIAN, 1911)        163       White: A. K. Rubinstein. Black: J....\n",
      "\n",
      "Page 3\n",
      "Section: ILLUSTRATIVE GAMES\n",
      "Text: 3. IRREGULAR DEFENCE (HAVANA, 1913)                     169       White: D. Janowski. Black: J. R. C...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show sample blocks with their section paths\n",
    "body_blocks = [b for b in all_blocks if b[\"type\"] == \"body\" and b[\"section_path\"]]\n",
    "\n",
    "print(\"Sample body text blocks with section paths:\\n\")\n",
    "for block in body_blocks[10:15]:  # Show middle section to avoid preamble\n",
    "    print(f\"Page {block['page_num']}\")\n",
    "    print(f\"Section: {block['section_path']}\")\n",
    "    print(f\"Text: {block['text'][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Enhanced Workspace\n",
    "\n",
    "Save the blocks with section paths for use in database creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved enhanced workspace to workspace_with_sections.json\n",
      "  - 1943 blocks\n",
      "  - 494 TOC entries\n",
      "  - 1934 blocks with section paths\n"
     ]
    }
   ],
   "source": [
    "workspace_enhanced = {\n",
    "    \"doc_id\": \"chess_pdf\",\n",
    "    \"num_pages\": len(doc),\n",
    "    \"blocks\": all_blocks,\n",
    "    \"toc\": toc\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "output_path = Path(\"workspace_with_sections.json\")\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(workspace_enhanced, f, indent=2)\n",
    "\n",
    "print(f\"Saved enhanced workspace to {output_path}\")\n",
    "print(f\"  - {len(all_blocks)} blocks\")\n",
    "print(f\"  - {len(toc)} TOC entries\")\n",
    "print(f\"  - {blocks_with_sections} blocks with section paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Design SQLite database schema\n",
    "- Create storage layer to persist this workspace\n",
    "- Build FTS5 full-text search index\n",
    "- Test retrieval with queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack-large-text-ASlkIg2G-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
