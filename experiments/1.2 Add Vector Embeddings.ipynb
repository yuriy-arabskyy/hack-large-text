{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Vector Embeddings to Parsed PDF Blocks\n",
    "\n",
    "This notebook enhances each block from the parsed PDF JSON with vector embeddings using sentence-transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuriyarabskyy/Library/Caches/pypoetry/virtualenvs/hack-large-text-ASlkIg2G-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize sentence-transformers model\n",
    "# Using all-MiniLM-L6-v2 - a lightweight and fast model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Model loaded: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parsed PDF JSON\n",
    "with open('workspace_with_sections.json', 'r') as f:\n",
    "    workspace_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: chess_pdf\n",
      "Number of pages: 95\n",
      "Number of blocks: 1943\n",
      "\n",
      "Sample block structure:\n",
      "{\n",
      "  \"page_num\": 0,\n",
      "  \"block_idx\": 0,\n",
      "  \"bbox\": [\n",
      "    33.75,\n",
      "    37.4498291015625,\n",
      "    456.353759765625,\n",
      "    138.7994384765625\n",
      "  ],\n",
      "  \"text\": \"The Project Gutenberg eBook of Chess Fundamentals      This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this ebook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook.\",\n",
      "  \"font_size\": 9.75,\n",
      "  \"font_name\": \"Menlo-Regular\",\n",
      "  \"is_bold\": false,\n",
      "  \"char_count\": 497,\n",
      "  \"type\": \"skip\",\n",
      "  \"section_path\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check structure\n",
    "print(f\"Document ID: {workspace_data['doc_id']}\")\n",
    "print(f\"Number of pages: {workspace_data['num_pages']}\")\n",
    "print(f\"Number of blocks: {len(workspace_data['blocks'])}\")\n",
    "print(f\"\\nSample block structure:\")\n",
    "print(json.dumps(workspace_data['blocks'][0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"Get embedding for a text string using sentence-transformers.\"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    embedding = model.encode(text, convert_to_numpy=True)\n",
    "    return embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings_to_blocks(blocks: List[Dict], batch_size: int = 32) -> List[Dict]:\n",
    "    \"\"\"Add embeddings to each block using batched encoding for efficiency.\"\"\"\n",
    "    enhanced_blocks = []\n",
    "    \n",
    "    # Collect texts and indices for batch processing\n",
    "    texts_to_embed = []\n",
    "    text_indices = []\n",
    "    \n",
    "    for i, block in enumerate(blocks):\n",
    "        if not block.get('text') or len(block['text'].strip()) < 3:\n",
    "            text_indices.append(None)\n",
    "        else:\n",
    "            text_indices.append(len(texts_to_embed))\n",
    "            texts_to_embed.append(block['text'].replace(\"\\n\", \" \"))\n",
    "    \n",
    "    # Generate embeddings in batches\n",
    "    print(f\"Generating embeddings for {len(texts_to_embed)} blocks...\")\n",
    "    embeddings = model.encode(\n",
    "        texts_to_embed, \n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    \n",
    "    # Add embeddings to blocks\n",
    "    for i, block in enumerate(blocks):\n",
    "        enhanced_block = block.copy()\n",
    "        \n",
    "        if text_indices[i] is None:\n",
    "            enhanced_block['embedding'] = None\n",
    "        else:\n",
    "            enhanced_block['embedding'] = embeddings[text_indices[i]].tolist()\n",
    "        \n",
    "        enhanced_blocks.append(enhanced_block)\n",
    "    \n",
    "    return enhanced_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 1941 blocks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 61/61 [00:08<00:00,  7.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process all blocks\n",
    "enhanced_blocks = add_embeddings_to_blocks(workspace_data['blocks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced workspace data\n",
    "enhanced_workspace = workspace_data.copy()\n",
    "enhanced_workspace['blocks'] = enhanced_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: The Project Gutenberg eBook of Chess Fundamentals      This ebook is for the use of anyone anywhere ...\n",
      "Embedding dimensions: 384\n",
      "First 5 values: [0.02042297087609768, -0.02423093654215336, -0.059918925166130066, -0.10673654824495316, 0.0003949103702325374]\n"
     ]
    }
   ],
   "source": [
    "# Check a sample embedding\n",
    "sample_block_with_embedding = next(b for b in enhanced_blocks if b['embedding'] is not None)\n",
    "print(f\"Sample text: {sample_block_with_embedding['text'][:100]}...\")\n",
    "print(f\"Embedding dimensions: {len(sample_block_with_embedding['embedding'])}\")\n",
    "print(f\"First 5 values: {sample_block_with_embedding['embedding'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced workspace saved to workspace_with_embeddings.json\n"
     ]
    }
   ],
   "source": [
    "# Save enhanced workspace\n",
    "output_path = 'workspace_with_embeddings.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(enhanced_workspace, f, indent=2)\n",
    "\n",
    "print(f\"Enhanced workspace saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics:\n",
      "Total blocks: 1943\n",
      "Blocks with embeddings: 1941\n",
      "Blocks without embeddings: 2\n"
     ]
    }
   ],
   "source": [
    "# Statistics\n",
    "blocks_with_embeddings = sum(1 for b in enhanced_blocks if b['embedding'] is not None)\n",
    "blocks_without_embeddings = len(enhanced_blocks) - blocks_with_embeddings\n",
    "\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"Total blocks: {len(enhanced_blocks)}\")\n",
    "print(f\"Blocks with embeddings: {blocks_with_embeddings}\")\n",
    "print(f\"Blocks without embeddings: {blocks_without_embeddings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack-large-text-ASlkIg2G-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
